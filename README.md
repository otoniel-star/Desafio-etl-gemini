üöÄ Relat√≥rio de Projeto: Pipeline de ETL com IA Generativa
1. O Desafio
O objetivo deste projeto foi construir um pipeline de ETL (Extract, Transform, Load) capaz de ler uma base de dados de clientes, utilizar Intelig√™ncia Artificial o chat gpt mas eu preferi optar pelo (Google Gemini) para gerar mensagens de marketing personalizadas para cada um e salvar o resultado de forma organizada.

2. Tecnologias Utilizadas
Linguagem: Python 3.12

Manipula√ß√£o de Dados: Pandas

Intelig√™ncia Artificial: Google GenAI SDK (Gemini 2.5 Flash Lite)

Controle de Fluxo: Time & OS (Bibliotecas padr√£o)

3. A Jornada de Desenvolvimento
Fase 1: Fundamenta√ß√£o e Extra√ß√£o (Extract)
Inicialmente, exploramos a diferen√ßa entre bancos relacionais (SQL) e n√£o-relacionais (NoSQL), entendendo que para este projeto, lidar√≠amos com dados tabulares (CSV).

A√ß√£o: Criamos um script gerador de dados (gerador_dados.py) que simulou uma base de 1.000 clientes com nomes e interesses financeiros variados (Cripto, FIIs, A√ß√µes).

Fase 2: Primeira Implementa√ß√£o e Obst√°culos
Na primeira vers√£o do ETL, utilizamos a abordagem cl√°ssica com pandas.apply() para processar a IA linha a linha. Enfrentamos tr√™s problemas cr√≠ticos:

Deprecia√ß√£o de SDK: A biblioteca google.generativeai entrou em modo de manuten√ß√£o.

Solu√ß√£o: Migramos para a nova SDK google.genai, garantindo longevidade ao c√≥digo.

Rate Limiting (Erro 429): O plano gratuito do Google bloqueou as requisi√ß√µes por excesso de velocidade ao tentar processar 1.000 linhas de uma vez.

Perda de Dados em Mem√≥ria: Ao interromper o script (ou em caso de falha), todo o progresso era perdido, pois o salvamento ocorria apenas no final.

Fase 3: Engenharia e Resili√™ncia (Transform)
Para tornar o script robusto ("A prova de falhas"), implementamos solu√ß√µes de Engenharia de Dados avan√ßadas:

L√≥gica de Retry (Backoff): Criamos um loop while que identifica o erro 429 (Resource Exhausted). Quando detectado, o script "dorme" por 60 segundos e tenta novamente, sem quebrar a execu√ß√£o.

Persist√™ncia de Estado (Checkpoint): Substitu√≠mos o processamento em mem√≥ria por um loop for que salva no disco r√≠gido (mode='a') a cada linha processada.

Filtro Inteligente: O script verifica quais IDs j√° foram salvos no CSV de sa√≠da e processa apenas o que falta (Delta Load). Isso permite parar e continuar o script a qualquer momento.

Engenharia de Prompt: Refinamos o prompt para solicitar respostas de "M√°ximo 12 palavras". Isso economizou tokens e acelerou o tempo de resposta da API.

Fase 4: Carregamento e Apresenta√ß√£o (Load)
O arquivo final gerado (.csv) apresentou problemas de formata√ß√£o ao abrir no Excel brasileiro (conflito de separadores , vs ;).

Solu√ß√£o: Criamos um script final de convers√£o que l√™ o CSV bruto processado e exporta para um arquivo Excel nativo (.xlsx), pronto para ser entregue ao time de neg√≥cios.

4. Resultados Alcan√ßados
‚úÖ Pipeline 100% automatizado e resiliente a falhas de rede/API. ‚úÖ Capacidade de processar grandes volumes de dados respeitando limites do Free Tier. ‚úÖ Custo zero de infraestrutura (rodando localmente com API gratuita). ‚úÖ Gera√ß√£o de mensagens de marketing altamente personalizadas.
